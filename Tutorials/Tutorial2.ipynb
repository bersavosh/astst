{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Name: \n",
    "\n",
    "---\n",
    "\n",
    "# Tutorial 2: Basics of inference\n",
    "\n",
    "All the parts that require action (either in the code or equations) are flagged by `<your turn>` or $\\color{red}{<your~turn>}$\n",
    "\n",
    "Quick note: if you see the warning `invalid value encountered`, it doesn't crash the cell/notebook. The results may still be valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emcee\n",
    "from scipy.integrate import quad\n",
    "import scipy.stats as st\n",
    "from scipy.misc import derivative\n",
    "from scipy.optimize import curve_fit, minimize, fsolve\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "# Below is a set of colors for matplotlib that is colorblind-friendly\n",
    "# To use them in plotting commands, you can simply set \"color=colorset[N]\",\n",
    "# where N is an integer in [0,16), reflecting the index of the colors below.\n",
    "colorset = ['#000000','#00270C','#00443C','#005083',\n",
    "            '#034BCA','#483CFC','#9C2BFF','#EB24F4',\n",
    "            '#FF2DC2','#FF4986','#FF7356','#FFA443',\n",
    "            '#EBD155','#D3F187','#D7FFC8','#FFFFFF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. Estimating source flux based on observations\n",
    "\n",
    "We observe a star with a telescope/detector over a series of $N$ measurements, where the $i^{\\rm{th}}$ measurement yields a flux of $F_i$ and a (gaussian) flux uncertainty of $e_i$. Given this set of measurements, and assuming that the source flux is constant over time, what is our best estimate of the true flux $F_\\rm{true}$?\n",
    "\n",
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.loadtxt('Data_T2_F.txt')\n",
    "e = np.loadtxt('Data_T2_dF.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "- Check number of measurements\n",
    "- Make a [forrest plot](https://en.wikipedia.org/wiki/Forest_plot) for the measurements and uncertainties (Flux measurements on the x-axis). To do this, you can simply use `plt.errorbar()` in matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# <your turn>\n",
    "\n",
    "\n",
    "# Plot cosmetics\n",
    "ax.set_xlabel('F',fontsize=20)\n",
    "ax.set_ylabel('Obs number', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and parametrization:\n",
    "The assumptions are straight-forward and the model is trivial: source is not variable, and the connection between what we measure and what we aim to estimate is clear:\n",
    "\n",
    "$$ F_\\rm{true} \\sim  D $$\n",
    "\n",
    "Where $D = \\{D_1,\\cdots,D_i\\,\\cdots,D_N\\}$ is the entire set of measurements, in which each single measurement is $D_i = (F_i,e_i)$.\n",
    "\n",
    "### Approach A: Frequentist\n",
    "\n",
    "Let's use maximum likelihood. We construct the likelihood function:\n",
    "$$\\mathcal{L}(D|F_{\\rm{true}}) = \\prod_{i=1}^N P(D_i|F_{\\rm{true}}) $$\n",
    "\n",
    "Where:\n",
    "$$ P(D_i|F_{\\rm{true}}) = ~\\color{red}{<your~turn>}$$\n",
    "\n",
    "It is often more convenient to instead compute the log-likelihood. So combining the previous two equations and retaining only the terms that depend on both data and model:\n",
    "\n",
    "$$ \\ln\\mathcal{L} = ~\\color{red}{<your~turn>}$$\n",
    "\n",
    "\n",
    "Our goal is to maximize the likelihood function above. In this particular case, we can even do it analytically. However, we will stick to numerical approach here to get familiar with the method.\n",
    "\n",
    "#### Based on the discussion above, write a python function for the (log-)likelihood function and find the best-fit values for parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>: Based on the equations above, define the likelihood function we'd want to maximize\n",
    "# Then use basic optimization methods to find the \"best-fit\" values for parameters.\n",
    "# Hint: you can use scipy.minimize and the negative log-likelihood function!\n",
    "\n",
    "def loglikelihood(F_true, F, e):\n",
    "    # <your turn>\n",
    "    \"\"\"\n",
    "    F_true is what we want to estimate (e.i., want to know the likelihood as a function of this value).\n",
    "    \n",
    "    F and e are the measurements and their uncertainties, respectively.\n",
    "    \n",
    "    This function should return the likelihood estimate for any F_true.\n",
    "    \"\"\"\n",
    "        \n",
    "    return \n",
    "\n",
    "def negloglikelihood(F_true, F, e):\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "# Fill the definition for the variable below based on your method\n",
    "results_frequentist = \n",
    "\n",
    "print(f'\\nFrequentist best-fit value: {results_frequentist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the log-likelihood function (or negative of it) and indicate the best-fit value found in the cell above on top of it (e.g., using `axvline` in `matplotlib`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn> : define variables and calculations you may need here.\n",
    "\n",
    "\n",
    "# Initiating the figure\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# <your turn> : add your plotting commands here.\n",
    "\n",
    "# Plot cosmetics - feel free to edit.\n",
    "ax.set_xlabel('F',fontsize=20)\n",
    "ax.set_ylabel('$-\\log\\mathcal{L}$',fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach B: Bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to compute is our knowledge of the parameters in question ($F$ in this case):\n",
    "\n",
    "$$ P(F_{\\rm{true}} | D) = \\frac{P(F_{\\rm{true}})~P(D|F_{\\rm{true}})}{P(D)}$$\n",
    "\n",
    "In practice, $P(D)$ amounts to normalization, thus leaving us with the posterior:\n",
    "\n",
    "$$ P(F_{\\rm{true}} | D) \\propto P(F_{\\rm{true}})~P(D|F_{\\rm{true}})$$\n",
    "\n",
    "Where $P(D|F_{\\rm{true}}) = \\mathcal{L}(D|F_{\\rm{true}})$ is the likelihood that we calculated in approach A.\n",
    "\n",
    "It is generally easier to do this in the log-space:\n",
    "$$ \\log P(F_{\\rm{true}} | D) \\propto \\log P(F_{\\rm{true}}) + \\log P(D|F_{\\rm{true}})$$\n",
    "\n",
    "\n",
    "So with all that, let's define functions for the log-prior and log-posterior (assuming the same definition and assignment for the likelihood as approach A):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>: define functions for the log-prior and log-posterior.\n",
    "# Note: log-likelihood is the same as in the frequentist approach, so we don't need to redefine it.\n",
    "\n",
    "def log_prior(F_true):\n",
    "    # Assume flat prior between 1150 and 1300\n",
    "    return \n",
    "\n",
    "def log_posterior(F_true, F, e):\n",
    "    return \n",
    "\n",
    "\n",
    "# If your prior is well-defined and normalized, the following should return ~1.0.\n",
    "print(f'Testing your log-prior, its integral from 1000 to 2000 is roughly:\\\n",
    "      {quad(lambda x: np.exp(log_prior(x)), 1000,2000)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: note that we built everything in $\\log$ space, not linear.**\n",
    "\n",
    "#### Now, similar to the frequentist approach, find the best-fit value for $F_\\textrm{true}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn> \n",
    "\n",
    "\n",
    "\n",
    "# Fill the definition for the variable below based on your method\n",
    "results_bayesian = \n",
    "\n",
    "print(f'\\nBayesian best-fit value: {results_bayesian}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bayesian approach, we are, simply put, \"updating\" information from prior to posterior based on new data. So, it is important to compare prior to posterior distribution to see the impact of our new data.\n",
    "\n",
    "#### Plot the prior and posterior distribution together and compare.\n",
    "\n",
    "*Note: As you will see, the scale of posterior and prior functions are significantly different (why?). Thus, we will use a simple matplotlib trick to over plot them with different y-axis while sharing the X-axis*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn> : define variables and calculations you may need here.\n",
    "\n",
    "# Initiating the figure\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# <your turn> : add your plotting commands for the *prior* here.\n",
    "\n",
    "\n",
    "# Plot cosmetics - feel free to edit.\n",
    "ax.set_xlabel('F',fontsize=20)\n",
    "ax.set_ylabel('Prior PDF(F)',fontsize=20)\n",
    "ax.set(xlim=[1100,1350])\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)\n",
    "# This is where we add a new \"axis\" on the same plot.\n",
    "ax2 = ax.twinx()\n",
    "# <your turn> : add your plotting commands for the *posterior* here.\n",
    "\n",
    "\n",
    "# Plot cosmetics - feel free to edit.\n",
    "ax2.set_xlabel('F',fontsize=20)\n",
    "ax2.set_ylabel('Posterior(F)',fontsize=20)\n",
    "ax2.set(xlim=[1100,1350])\n",
    "ax2.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax2.tick_params(axis='both', which='major', length=5)\n",
    "ax2.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax2.tick_params(axis='both', which='both',direction='in',right=True,top=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is the posterior function values so small? Can it actually be considered a PDF?\n",
    "\n",
    "We ignored the model evidence term which while not impacting the best-fit value, it normalizes the posterior function, turning it into a PDF where $\\int P(F|D) dF = 1$.\n",
    "\n",
    "In the simplest cases like this (simple likelihoods, low-dimension parameter space), calculating posterior directly/analytically is very simple and straight forward. This can quickly change and get complicated (especially for the \"*evidence*\"). Hence, this underlines the importance of MCMC methods: they can fairly sample from a **ill-normalized** posterior.\n",
    "\n",
    "So, in principle, an MCMC is not appropriate for our case here (as with a little bit of math, we can calculate the model evidence term and normalize the posterior nicely), but as we are trying to get familiar with techniques for more complex scenarios, we assume that the normization is difficult to estimate and use a simple MCMC sampling implementation.\n",
    "\n",
    "So, **the output of MCMC instead of being a functional form of the posterior PDF, will be a sample that (assuming a successful MCMC run) is a fair sample from the posterior PDF**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)    # To track the randomness\n",
    "\n",
    "# MCMC setup and execution:\n",
    "ndim = 1       # number of parameters in the model\n",
    "nwalkers = 50  # number of MCMC walkers\n",
    "nburn = 1000   # \"burn-in\" period to let chains stabilize\n",
    "nsteps = 4000  # number of MCMC steps to take (after burn-in)\n",
    "\n",
    "# we'll start at random locations between 0 and 3000\n",
    "starting_guesses = 3000 * np.random.rand(nwalkers, ndim)\n",
    "\n",
    "# Now we start the sampler using the log_posterior:\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, args=[F, e])\n",
    "sampler.run_mcmc(starting_guesses, nsteps)\n",
    "\n",
    "#Extracting the posterior sample result\n",
    "#posterior_sample = sampler.chain                               # shape = (nwalkers, nsteps, ndim)\n",
    "posterior_sample = sampler.chain[:, nburn:, :].ravel()         # discard burn-in points\n",
    "\n",
    "# <your turn>: The process above grabs your log_posterior and samples from it in a fair way. \n",
    "# Now the variable \"posterior_sample\" contains the result of this MCMC process. \n",
    "# Based on this, Perform a Bayesian point-estimation and report a \"best-fit\" value.\n",
    "\n",
    "\n",
    "bayesian_point_estimate = \n",
    "print('F posterior median:',bayesian_point_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the walkers and their convergence\n",
    "\n",
    "The walkers' steps (i.e., the posterior sample) is stored in `sampler.chain` above, which is an array with dimensions $N_{walkers} \\times N_{steps} \\times N_{parameters}$ . When we make `posterior_sample`, we basically remove the first 1000 steps as the *burn-in*, and then *flatten* the array (i.e., make a 1-D array concatenating all the walkers into the same array to make a single sample for each parameter).\n",
    "\n",
    "But let's explore how our walkers have walked. Choose a few walkers (say, 5 or 10) from `sampler.chain` (not all 50) and plot the first 200 steps for each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn> : \n",
    "\n",
    "# Initiating the figure\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# <your turn> : add your plotting commands here. If you label them properly, they will show up in the legend.\n",
    "\n",
    "\n",
    "# Plot cosmetics - feel free to edit.\n",
    "ax.set_xlabel('Step number',fontsize=20)\n",
    "ax.set_ylabel('Walker value for F',fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's repeat the same last step but plot the last 3000 steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn> : \n",
    "\n",
    "# Initiating the figure\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# <your turn> : add your plotting commands here. If you label them properly, they will show up in the legend.\n",
    "\n",
    "\n",
    "# Plot cosmetics - feel free to edit.\n",
    "ax.set_xlabel('Step number',fontsize=20)\n",
    "ax.set_ylabel('Walker value for F',fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, plot the posterior sample against the prior PDF.\n",
    "*Hint: You can use the keyword `density = True` in a matplotlib histogram to make it normalized, so that it sums to 1.0*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn> : define variables and calculations you may need here.\n",
    "\n",
    "\n",
    "# Initiating the figure\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# <your turn> : add your plotting commands here. If you label them properly, they will show up in the legend.\n",
    "\n",
    "# Plot cosmetics - feel free to edit.\n",
    "ax.legend(fontsize=20)\n",
    "ax.set_xlabel('F',fontsize=20)\n",
    "ax.set_ylabel('Prob. Density',fontsize=20)\n",
    "ax.set(xlim=[1100,1350])\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the impact of prior on the results\n",
    "\n",
    "With a uniform prior in this problem, the results from both frequentist and bayesian methods are very well consistent with each other. But a more restrictive/constrained prior can lead to a different result. \n",
    "\n",
    "We are going to briefly explore that in this problem:\n",
    "\n",
    "#### Redefine the prior, this time so that the propbability of getting a value $F<1240$ is $\\approx 0$. Perform a bayesian point estimation on the result and plot the results, similar to the last few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### <your turn>\n",
    "def informed_log_prior1(F_true):\n",
    "    return\n",
    "\n",
    "# Same posterior as before, with the prior replaced\n",
    "def informed_log_posterior1(F_true, F, e):\n",
    "    return informed_log_prior1(F_true) + loglikelihood(F_true, F, e)\n",
    "\n",
    "# MCMC setup and execution:\n",
    "ndim = 1       # number of parameters in the model\n",
    "nwalkers = 50  # number of MCMC walkers\n",
    "nburn = 1000   # \"burn-in\" period to let chains stabilize\n",
    "nsteps = 4000  # number of MCMC steps to take (after burn-in)\n",
    "\n",
    "# we'll start at random locations between 0 and 3000\n",
    "starting_guesses = 3000 * np.random.rand(nwalkers, ndim)\n",
    "\n",
    "# Now we start the sampler using the log_posterior:\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, informed_log_posterior1, args=[F, e])\n",
    "sampler.run_mcmc(starting_guesses, nsteps)\n",
    "\n",
    "#Extracting the posterior sample result\n",
    "#posterior_sample = sampler.chain                               # shape = (nwalkers, nsteps, ndim)\n",
    "informed_posterior_sample1 = sampler.chain[:, nburn:, :].ravel()         # discard burn-in points\n",
    "\n",
    "# <your turn>: Bayesian point estimation\n",
    "\n",
    "# <your turn>: Plotting prior and posterior\n",
    "# define variables and calculations you may need here.\n",
    "\n",
    "# Initiating the figure\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# <your turn> : add your plotting commands here. If you label them properly, they will show up in the legend.\n",
    "\n",
    "# Plot cosmetics - feel free to edit.\n",
    "ax.legend(fontsize=20)\n",
    "ax.set_xlabel('F',fontsize=20)\n",
    "ax.set_ylabel('Prob. Density',fontsize=20)\n",
    "ax.set(xlim=[1100,1350])\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the last step, but replace the prior with a gaussian prior.\n",
    "*Note: Remember, it is better if the prior is normalized (for plotting).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### <your turn>\n",
    "def informed_log_prior2(F_true):\n",
    "    mu = 1250\n",
    "    sd = 10\n",
    "    like = 1./(np.sqrt(2.*np.pi)*sd)*np.exp(-np.power((F_true - mu)/sd, 2.)/2)\n",
    "    if like > 0:\n",
    "        return np.log(like)\n",
    "    else:\n",
    "        return -np.inf\n",
    "\n",
    "# Same posterior as before, with the prior replaced\n",
    "def informed_log_posterior2(F_true, F, e):\n",
    "    return informed_log_prior2(F_true) + loglikelihood(F_true, F, e)\n",
    "\n",
    "# MCMC setup and execution:\n",
    "ndim = 1       # number of parameters in the model\n",
    "nwalkers = 50  # number of MCMC walkers\n",
    "nburn = 1000   # \"burn-in\" period to let chains stabilize\n",
    "nsteps = 4000  # number of MCMC steps to take (after burn-in)\n",
    "\n",
    "# we'll start at random locations between 0 and 3000\n",
    "starting_guesses = 3000 * np.random.rand(nwalkers, ndim)\n",
    "\n",
    "# Now we start the sampler using the log_posterior:\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, informed_log_posterior2, args=[F, e])\n",
    "sampler.run_mcmc(starting_guesses, nsteps)\n",
    "\n",
    "#Extracting the posterior sample result\n",
    "#posterior_sample = sampler.chain                               # shape = (nwalkers, nsteps, ndim)\n",
    "informed_posterior_sample2 = sampler.chain[:, nburn:, :].ravel()         # discard burn-in points\n",
    "\n",
    "# <your turn>: Bayesian point estimation\n",
    "print('F posterior median:',np.median(informed_posterior_sample2))\n",
    "\n",
    "# <your turn>: Plotting prior and posterior\n",
    "\n",
    "# <your turn> : define variables and calculations you may need here.\n",
    "test_x = np.linspace(1100,1400,1000)\n",
    "test_y = [np.exp(informed_log_prior2(i)) for i in test_x]\n",
    "\n",
    "# Initiating the figure\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# <your turn> : add your plotting commands here. If you label them properly, they will show up in the legend.\n",
    "\n",
    "ax.hist(informed_posterior_sample2, bins=500, histtype='step', lw=2, alpha=0.8, density=True, label=r'P(F|D)',color=colorset[4])\n",
    "ax.plot(test_x,test_y,lw=2, alpha=0.8,label=r'P(F)', color=colorset[8])\n",
    "\n",
    "# Plot cosmetics - feel free to edit.\n",
    "ax.legend(fontsize=20)\n",
    "ax.set_xlabel('F',fontsize=20)\n",
    "ax.set_ylabel('Prob. Density',fontsize=20)\n",
    "ax.set(xlim=[1100,1350])\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval estimation\n",
    "\n",
    "### Fisher information\n",
    "\n",
    "Estimate the uncertainty on each parameter using the Fisher information.\n",
    "\n",
    "*Hint: You can use the python function `derivative` under `scipy.misc` (which is already imported in this notebook).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n",
    "\n",
    "fisher_delta_f = \n",
    "\n",
    "print(f'F_true: {results_frequentist} +/- {fisher_delta_f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta statistics\n",
    "\n",
    "Define a statistic (e.g., $\\chi^2$ statsitc), plot the statistic as a function of the parameter model you're fitting and indicate the 1-$\\sigma$ threshold on the plot (using `axhline()` in matplotlib). Then estimate the 1-$\\sigma$ uncertainties using the $\\Delta$ method.\n",
    "\n",
    "First let's define the statistic function and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>: Define a chi-squared function\n",
    "def chi2(F_true, F, e):\n",
    "    return \n",
    "\n",
    "# <your turn> : define variables and calculations you may need here.\n",
    "# Hint: Plot the F_true values between 1225 and 1243\n",
    "\n",
    "# Initiating the figure\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# <your turn> : add your plotting commands here. If you label them properly, they will show up in the legend.\n",
    "\n",
    "# Plot cosmetics - feel free to edit.\n",
    "ax.set_xlabel('F',fontsize=20)\n",
    "ax.set_ylabel(r'$\\chi^2$',fontsize=20)\n",
    "ax.set(xlim=[1225,1243])\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, estimate the value of $F$ at 1-$\\sigma$.\n",
    "\n",
    "*Hint: You can define a function based on $\\chi^2$ that evaluates to 0 at the 1-$\\sigma$ points, then use implemented methods (like `fsolve` in `scipy.optimize`) to find its roots.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn> : Just define the function that would evaluate to zero at the 1-sigma points\n",
    "\n",
    "def delta_1sig(F_true, F, e):\n",
    "    return \n",
    "\n",
    "\n",
    "# If your function is correct, these should return meaningful results\n",
    "deltastats_lower_bound = fsolve(delta_1sig,results_frequentist-1,args=(F,e))[0]\n",
    "deltastats_upper_bound = fsolve(delta_1sig,results_frequentist+1,args=(F,e))[0]\n",
    "print(f'Uncertainty bounds - lower: {deltastats_lower_bound}, upper:{deltastats_upper_bound}')\n",
    "\n",
    "deltastats_lower_uncert = results_frequentist - deltastats_lower_bound \n",
    "deltastats_upper_uncert = deltastats_upper_bound - results_frequentist\n",
    "\n",
    "print(f'F_true: {results_frequentist} (-{deltastats_lower_uncert}/+{deltastats_upper_uncert})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interval between these uncertainties is refered to as the 1-$\\sigma$ (68%) **confidence interval** in frequentist inference.\n",
    "\n",
    "**Note: Remember that `fsolve` returns the points where the function hits 1-$\\sigma$ here, the returned values are not the actual uncertainty! but the best fit value $\\pm$ the 1-$\\sigma$ uncertainty.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap (Monte-Carlo)\n",
    "\n",
    "Let's first make sure we can simulate a mock data set which shares the properties of our data set. For this purpose, our aim **in this specific example** is consider the uncertainty in parameters, mainly due to the uncertainties in the data. Given through out this example we **assume data uncertainties are gaussian**, we simply resample each data point $i$, assuming $\\mathcal{N}(y_i,\\delta y_i)$.\n",
    "\n",
    "**Remember that boostrap method depends entirely on assumptions in the simulation!**\n",
    "\n",
    "So, with that in mind, create a single mock data set based on our data and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>: construct a single bootstrap simulation \n",
    "# Remember: You are not simulating \"e\" values, just \"F\" values\n",
    "# So the variable below should be a simulation of the \"F\" data array\n",
    "bootstrap_data = \n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# <your turn>: add plotting commands here\n",
    "# Note: your bootsrap simulation will have the same errorbar/uncertainty as the data\n",
    "\n",
    "\n",
    "# Plot cosmetics\n",
    "ax.legend(fontsize=18)\n",
    "ax.set_xlabel('F',fontsize=20)\n",
    "ax.set_ylabel('Obs number', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do this iteratively to generate a large enough sample that would represent the propagation of uncertainties in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>: Simply fill the definition for \"bootstrap_data\" below based on your definition above\n",
    "n_bootstrap = 10000\n",
    "Ftrue_bootstrap = []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    bootstrap_data =   # Add the definition HERE!\n",
    "    iteration_best_fit = minimize(negloglikelihood,1000,args=(bootstrap_data,e)).x[0]\n",
    "    Ftrue_bootstrap.append(iteration_best_fit)\n",
    "\n",
    "# Initiating the figure\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(Ftrue_bootstrap, bins=20, edgecolor='w',lw=2, alpha=0.8, color=colorset[4])\n",
    "\n",
    "# Plot cosmetics\n",
    "ax.set_xlabel('F',fontsize=20)\n",
    "ax.set_ylabel('#simulations',fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='major', length=5)\n",
    "ax.tick_params(axis='both', which='minor', length=2.5)\n",
    "ax.tick_params(axis='both', which='both',direction='in',right=True,top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Now, use sample quantiles to estimate the uncertainties from the bootstrap sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>: \n",
    "MC_lower_bound = \n",
    "MC_upper_bound = \n",
    "print(f'Uncertainty bounds - lower: {MC_lower_bound}, upper:{MC_upper_bound}')\n",
    "\n",
    "MC_lower_uncert = results_frequentist - MC_lower_bound \n",
    "MC_upper_uncert = MC_upper_bound - results_frequentist\n",
    "\n",
    "print(f'F_true: {results_frequentist} (-{MC_lower_uncert}/+{MC_upper_uncert})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian point-estimation based on MCMC\n",
    "\n",
    "Well, you already have the posterior sample (`posterior_sample`)! So, it would simply be a quantile estimation like for the bootstrapped sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>: \n",
    "MCMC_lower_bound = \n",
    "MCMC_upper_bound = \n",
    "\n",
    "print(f'Uncertainty bounds - lower: {MCMC_lower_bound}, upper:{MCMC_upper_bound}')\n",
    "\n",
    "MCMC_lower_uncert = results_bayesian - MCMC_lower_bound \n",
    "MCMC_upper_uncert = MCMC_upper_bound - results_bayesian\n",
    "\n",
    "print(f'F_true: {results_frequentist} (-{MCMC_lower_uncert}/+{MCMC_upper_uncert})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interval between these uncertainties is refered to as the 1-$\\sigma$ (68%) **credible interval** in bayesian inference.\n",
    "\n",
    "## Difference between the meaning of confidence and credible intervals:\n",
    "\n",
    "While the values are pretty similar in our case here, their philosophical meanings is vastly different. Quoting Jake vanderPlas:\n",
    "\n",
    "\"There is a 68% probability that when we compute $F$ from data of this sort, the true mean will fall within the **confidence interval**.\" - Frequentists\n",
    "\n",
    "\"Given our observed data, there is a 68% probability that the true value of $F$ falls within the **credible interval**\" - Bayesians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can now save the notebook and download it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "bayes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
